# 🧠 ReliefConnect AI Service

Intelligent backend for disaster-relief product recommendations and chat-based assistance. Built with FastAPI, LangGraph, OpenAI GPT-4o-mini, and Chroma Vector DB.

# 🚀 Overview

The AI Service powers the ReliefConnect chatbot, providing:

Intelligent classification of user intent (product, order, fraud, or other)

Vector-based product recommendations using ChromaDB

Context-aware summaries generated by OpenAI LLMs

Persistent, session-based chat memory for personalized conversations

This service runs independently and connects to the Node.js backend or directly to the React UI through REST APIs.


# 🧱 Tech Stack
| **Layer** | **Technology** | **Description** |
|------------|----------------|-----------------|
| API Framework | 🦋 **FastAPI** | RESTful service for LLM orchestration |
| LLM Orchestration | 🧩 **LangGraph** | Manages flow between intent classification, search, and summarization |
| Embedding DB | 🧠 **ChromaDB** | Vector database for semantic search |
| LLM Model | 🤖 **OpenAI gpt-4o-mini** | Powers classification and summarization |
| Embedding Model | 🧬 **text-embedding-3-small** | Used to encode product descriptions |
| Data Exchange | 🌐 **JSON over HTTP** | Connects with Node.js backend and React frontend 

# ⚙️ Installation & Setup
## 1️⃣ Clone the Repository
git clone https://github.com/<your-username>/ReliefConnect.git
cd ReliefConnect/ai-service

## 2️⃣ Create a Virtual Environment
python -m venv venv
source venv/bin/activate       # macOS/Linux
venv\Scripts\activate          # Windows

## 3️⃣ Install Dependencies
pip install -r requirements.txt


Example requirements.txt:

fastapi
uvicorn
pydantic
langchain
langchain-openai
langgraph
chromadb
python-dotenv

## 4️⃣ Environment Variables (.env)

Create a .env file in the root directory:

OPENAI_API_KEY=your_openai_key_here

CHROMA_DB_PATH=../server/vector/chroma_data

HOST=localhost

PORT=8001

## ▶️ Running the Service
uvicorn app:app --host localhost --port 8001 --reload

The API will start at: http://localhost:8001

Example endpoint:
POST http://localhost:8001/recommend

# 📬 Example Request
curl -X POST http://localhost:8001/recommend \
  -H "Content-Type: application/json" \
  -d '{"query": "I need food and water for my family", "session_id": "sanjay_123"}'

# ✅ Example Response
```json
{
  "success": true,
  "intent": "product",
  "response": "Here are some relief products to help with food and water for your family:\n\n### 🍽️ Emergency Food Kit\n- **Description:** Non-perishable food items...\n- **Price:** $35\n\n### 💧 Clean Water Supplies\n- **Description:** Water purification tablets...",
  "products": [
    {
      "id": "kit-002",
      "name": "Emergency Food Kit",
      "category": "Food & Water"
    },
    {
      "id": "kit-007",
      "name": "Clean Water Supplies",
      "category": "Food & Water"
    }
  ]
}
```

# 🧠 Chat Memory

Each chat session is identified by a unique session_id.
The model maintains in-memory conversation history for the duration of the session:

session_memory = {
    "sanjay_123": [
        {"role": "user", "content": "I need temporary shelter"},
        {"role": "assistant", "content": "You can use our Emergency Shelter Kit..."}
    ]
}


If you restart the service, the session resets (ephemeral memory).
For persistence, integrate Redis or MongoDB later.

# 🧩 Directory Structure
```
ai-service/
├── app.py                   # FastAPI entry point
├── product_graph.py         # LangGraph workflow (intent → search → summarize)
├── chroma_client.py         # Chroma collection setup
├── .env                     # Environment variables
├── requirements.txt          # Dependencies
└── README.md                 # You are here 🚀
```

# 💡 Future Enhancements

 Add Redis session memory for persistent chat

 Support multi-intent classification (e.g., “food and shelter”)

 Fine-tune LLM responses for localized context

 Stream partial responses for real-time typing effect

 Integrate with ReliefConnect Node.js backend for order routing

# 🧔 Author

Sanjay Sakthivel
🎓 M.S. Computer Science — Illinois Institute of Technology
💻 AI Engineer & Full-Stack Developer


📜 License

This project is licensed under the MIT License — see the LICENSE file for details.