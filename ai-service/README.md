# ğŸ§  ReliefConnect AI Service

Intelligent backend for disaster-relief product recommendations and chat-based assistance. Built with FastAPI, LangGraph, OpenAI GPT-4o-mini, and Chroma Vector DB.

# ğŸš€ Overview

The AI Service powers the ReliefConnect chatbot, providing:

Intelligent classification of user intent (product, order, fraud, or other)

Vector-based product recommendations using ChromaDB

Context-aware summaries generated by OpenAI LLMs

Persistent, session-based chat memory for personalized conversations

This service runs independently and connects to the Node.js backend or directly to the React UI through REST APIs.


# ğŸ§± Tech Stack
| **Layer** | **Technology** | **Description** |
|------------|----------------|-----------------|
| API Framework | ğŸ¦‹ **FastAPI** | RESTful service for LLM orchestration |
| LLM Orchestration | ğŸ§© **LangGraph** | Manages flow between intent classification, search, and summarization |
| Embedding DB | ğŸ§  **ChromaDB** | Vector database for semantic search |
| LLM Model | ğŸ¤– **OpenAI gpt-4o-mini** | Powers classification and summarization |
| Embedding Model | ğŸ§¬ **text-embedding-3-small** | Used to encode product descriptions |
| Data Exchange | ğŸŒ **JSON over HTTP** | Connects with Node.js backend and React frontend 

# âš™ï¸ Installation & Setup
## 1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/ReliefConnect.git
cd ReliefConnect/ai-service

## 2ï¸âƒ£ Create a Virtual Environment
python -m venv venv
source venv/bin/activate       # macOS/Linux
venv\Scripts\activate          # Windows

## 3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


Example requirements.txt:

fastapi
uvicorn
pydantic
langchain
langchain-openai
langgraph
chromadb
python-dotenv

## 4ï¸âƒ£ Environment Variables (.env)

Create a .env file in the root directory:

OPENAI_API_KEY=your_openai_key_here

CHROMA_DB_PATH=../server/vector/chroma_data

HOST=localhost

PORT=8001

## â–¶ï¸ Running the Service
uvicorn app:app --host localhost --port 8001 --reload

The API will start at: http://localhost:8001

Example endpoint:
POST http://localhost:8001/recommend

# ğŸ“¬ Example Request
curl -X POST http://localhost:8001/recommend \
  -H "Content-Type: application/json" \
  -d '{"query": "I need food and water for my family", "session_id": "sanjay_123"}'

# âœ… Example Response
```json
{
  "success": true,
  "intent": "product",
  "response": "Here are some relief products to help with food and water for your family:\n\n### ğŸ½ï¸ Emergency Food Kit\n- **Description:** Non-perishable food items...\n- **Price:** $35\n\n### ğŸ’§ Clean Water Supplies\n- **Description:** Water purification tablets...",
  "products": [
    {
      "id": "kit-002",
      "name": "Emergency Food Kit",
      "category": "Food & Water"
    },
    {
      "id": "kit-007",
      "name": "Clean Water Supplies",
      "category": "Food & Water"
    }
  ]
}
```

# ğŸ§  Chat Memory

Each chat session is identified by a unique session_id.
The model maintains in-memory conversation history for the duration of the session:

session_memory = {
    "sanjay_123": [
        {"role": "user", "content": "I need temporary shelter"},
        {"role": "assistant", "content": "You can use our Emergency Shelter Kit..."}
    ]
}


If you restart the service, the session resets (ephemeral memory).
For persistence, integrate Redis or MongoDB later.

# ğŸ§© Directory Structure
```
ai-service/
â”œâ”€â”€ app.py                   # FastAPI entry point
â”œâ”€â”€ product_graph.py         # LangGraph workflow (intent â†’ search â†’ summarize)
â”œâ”€â”€ chroma_client.py         # Chroma collection setup
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ requirements.txt          # Dependencies
â””â”€â”€ README.md                 # You are here ğŸš€
```

# ğŸ’¡ Future Enhancements

 Add Redis session memory for persistent chat

 Support multi-intent classification (e.g., â€œfood and shelterâ€)

 Fine-tune LLM responses for localized context

 Stream partial responses for real-time typing effect

 Integrate with ReliefConnect Node.js backend for order routing

# ğŸ§” Author

Sanjay Sakthivel
ğŸ“ M.S. Computer Science â€” Illinois Institute of Technology
ğŸ’» AI Engineer & Full-Stack Developer


ğŸ“œ License

This project is licensed under the MIT License â€” see the LICENSE file for details.